{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script NLTK_Logistic_NaiveBayes_SVC_Regression_Restaurant_Reviews.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1754294249934,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "gbmghycMvy4H"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 15:22:46.438751: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import nltk\n",
    "\n",
    "\n",
    "# FOR LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1754294249967,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "nQhn-jMiwIA3",
    "outputId": "07e14bec-7243-4678-b23c-d615db02514a"
   },
   "outputs": [],
   "source": [
    "# ---- ensure NLTK data and then create stopwords/stemmer ----\n",
    "nltk.download('punkt', quiet=True)       # tokenizers/punkt\n",
    "nltk.download('stopwords', quiet=True)   # corpora/stopwords\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rk2sWemwr7cw"
   },
   "source": [
    "## **Clean and normalize text for ML.**\n",
    "Makes text more uniform, reduces noise, and simplifies vocabulary for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1754294249993,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "ndahDFECwRLy"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    tokens = text.split()\n",
    "\n",
    "    negation_words = {\"not\", \"no\", \"nor\", \"n't\"}\n",
    "    tokens = [word for word in tokens if word not in stop_words or word in negation_words]\n",
    "\n",
    "    # tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    tokens = [stemmer.stem(word) for word in tokens]  # Stemming\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1754294254704,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "dnozdCbcwR1r",
    "outputId": "394d6b5e-66bb-4166-cd3e-117a6151e7c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "df = pd.read_csv(\"./Restaurant_Reviews.tsv\", sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1754294254849,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "MjKmyJHswU0k",
    "outputId": "7fb52925-c48f-4767-bf55-e6f497abe9de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>clean_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>wow love place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>crust not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>not tasti textur nasti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>stop late may bank holiday rick steve recommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>select menu great price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "      <td>think food flavor textur lack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "      <td>appetit instantli gone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "      <td>overal not impress would not go back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>whole experi underwhelm think well go ninja su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hadnt wast enough life pour salt wound draw ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked  \\\n",
       "0                             Wow... Loved this place.      1   \n",
       "1                                   Crust is not good.      0   \n",
       "2            Not tasty and the texture was just nasty.      0   \n",
       "3    Stopped by during the late May bank holiday of...      1   \n",
       "4    The selection on the menu was great and so wer...      1   \n",
       "..                                                 ...    ...   \n",
       "995  I think food should have flavor and texture an...      0   \n",
       "996                           Appetite instantly gone.      0   \n",
       "997  Overall I was not impressed and would not go b...      0   \n",
       "998  The whole experience was underwhelming, and I ...      0   \n",
       "999  Then, as if I hadn't wasted enough of my life ...      0   \n",
       "\n",
       "                                          clean_Review  \n",
       "0                                       wow love place  \n",
       "1                                       crust not good  \n",
       "2                               not tasti textur nasti  \n",
       "3    stop late may bank holiday rick steve recommen...  \n",
       "4                              select menu great price  \n",
       "..                                                 ...  \n",
       "995                      think food flavor textur lack  \n",
       "996                             appetit instantli gone  \n",
       "997               overal not impress would not go back  \n",
       "998  whole experi underwhelm think well go ninja su...  \n",
       "999  hadnt wast enough life pour salt wound draw ti...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_Review'] = df['Review'].apply(preprocess)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwUVVmvitRaG"
   },
   "source": [
    "# **TF-IDF vectorisation**\n",
    "converts text into numerical vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1754294254859,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "OwSs40UVtVq9"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['clean_Review'])\n",
    "y = df['Liked']\n",
    "\n",
    "# map integer class indices back to original labels (useful for multiclass)\n",
    "label_classes = np.unique(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1754294254880,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "lmelmCwJtdR0",
    "outputId": "1e8fe206-936e-454f-bce9-b0d14bb10ae9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "995    0\n",
       "996    0\n",
       "997    0\n",
       "998    0\n",
       "999    0\n",
       "Name: Liked, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1754294254880,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "sWRFjDO1tffS",
    "outputId": "75d70a42-56f9-4a43-8fac-83b21fb44f94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x1612 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5645 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhX3a0K-y-lZ"
   },
   "source": [
    "# **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- BiLSTM: tokenizer + sequence prep (replace existing tokenizer block) ----\n",
    "vocab_size = 20000\n",
    "maxlen = 128\n",
    "oov_token = \"<OOV>\"\n",
    "\n",
    "# fallback: if Tokenizer not available from tf.keras, try keras package\n",
    "if Tokenizer is None:\n",
    "    try:\n",
    "        from keras.preprocessing.text import Tokenizer as TokenizerLocal\n",
    "        from keras.preprocessing.sequence import pad_sequences as pad_sequences_local\n",
    "        Tokenizer = TokenizerLocal\n",
    "        pad_sequences = pad_sequences_local\n",
    "    except Exception:\n",
    "        Tokenizer = None\n",
    "        pad_sequences = None\n",
    "\n",
    "if Tokenizer is not None:\n",
    "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "    # Use the cleaned review column you created earlier\n",
    "    if \"clean_Review\" in df.columns:\n",
    "        texts_for_tokenizer = df[\"clean_Review\"].astype(str).tolist()\n",
    "    else:\n",
    "        # fallback: apply preprocess to the original review column\n",
    "        texts_for_tokenizer = df[\"Review\"].astype(str).apply(preprocess).tolist()\n",
    "\n",
    "    tokenizer.fit_on_texts(texts_for_tokenizer)\n",
    "    sequences = tokenizer.texts_to_sequences(texts_for_tokenizer)\n",
    "    X_seq_all = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "else:\n",
    "    tokenizer = None\n",
    "    X_seq_all = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1754294254881,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "CiM8pFs2EjLq"
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# keep existing TF-IDF split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y if len(np.unique(y))>1 else None)\n",
    "\n",
    "# split sequences for BiLSTM (if available)\n",
    "if X_seq_all is not None:\n",
    "    Xs_train, Xs_test, ys_train, ys_test = train_test_split(X_seq_all, y, test_size=0.3, random_state=42, stratify=y if len(np.unique(y))>1 else None)\n",
    "else:\n",
    "    Xs_train = Xs_test = ys_train = ys_test = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1754294254881,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "P5LpVomsE3xD"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, name=\"Model\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n====== {name} ======\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1754294254964,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "z8VR5ncTE6i4",
    "outputId": "1db476a3-d034-4dee-c7dc-bca85cac4252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Logistic Regression ======\n",
      "Accuracy: 0.8166666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       150\n",
      "           1       0.84      0.79      0.81       150\n",
      "\n",
      "    accuracy                           0.82       300\n",
      "   macro avg       0.82      0.82      0.82       300\n",
      "weighted avg       0.82      0.82      0.82       300\n",
      "\n",
      "\n",
      "====== Naive Bayes ======\n",
      "Accuracy: 0.7966666666666666\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79       150\n",
      "           1       0.79      0.81      0.80       150\n",
      "\n",
      "    accuracy                           0.80       300\n",
      "   macro avg       0.80      0.80      0.80       300\n",
      "weighted avg       0.80      0.80      0.80       300\n",
      "\n",
      "\n",
      "====== Support Vector Classifier ======\n",
      "Accuracy: 0.8166666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       150\n",
      "           1       0.82      0.81      0.81       150\n",
      "\n",
      "    accuracy                           0.82       300\n",
      "   macro avg       0.82      0.82      0.82       300\n",
      "weighted avg       0.82      0.82      0.82       300\n",
      "\n",
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akashs/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757929968.608454   30886 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1648 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-09-15 15:22:50.994496: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.4937 - loss: 0.6934 - val_accuracy: 0.7143 - val_loss: 0.6900\n",
      "Epoch 2/6\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5810 - loss: 0.6877 - val_accuracy: 0.7714 - val_loss: 0.6775\n",
      "Epoch 3/6\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7286 - loss: 0.6610 - val_accuracy: 0.6143 - val_loss: 0.6383\n",
      "Epoch 4/6\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7794 - loss: 0.5656 - val_accuracy: 0.7143 - val_loss: 0.5183\n",
      "Epoch 5/6\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8333 - loss: 0.5587 - val_accuracy: 0.5857 - val_loss: 1.0742\n",
      "Epoch 6/6\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7349 - loss: 0.6739 - val_accuracy: 0.8143 - val_loss: 0.4267\n",
      "\n",
      "====== BiLSTM ======\n",
      "Accuracy: 0.7266666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.76       150\n",
      "           1       0.80      0.61      0.69       150\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.74      0.73      0.72       300\n",
      "weighted avg       0.74      0.73      0.72       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = train_and_evaluate_model(LogisticRegression(), X_train, y_train, X_test, y_test, name=\"Logistic Regression\")\n",
    "nb_model = train_and_evaluate_model(MultinomialNB(), X_train, y_train, X_test, y_test, name=\"Naive Bayes\")\n",
    "svc_model = train_and_evaluate_model(SVC(kernel='linear'), X_train, y_train, X_test, y_test, name=\"Support Vector Classifier\")\n",
    "\n",
    "\n",
    "# ---- Train BiLSTM ----\n",
    "bilstm_model = None\n",
    "if tf is None:\n",
    "    print(\"TensorFlow not available — skipping BiLSTM.\")\n",
    "else:\n",
    "    if Xs_train is None:\n",
    "        print(\"No tokenized sequence data (Xs_train is None). Ensure tokenizer and X_seq_all were created.\")\n",
    "    else:\n",
    "        embed_dim = 100\n",
    "        lstm_units = 128\n",
    "        batch_size = 64\n",
    "        epochs = 6\n",
    "\n",
    "        n_classes = len(np.unique(ys_train))\n",
    "        if n_classes > 2:\n",
    "            # multiclass\n",
    "            bilstm_model = Sequential([\n",
    "                Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=maxlen),\n",
    "                Bidirectional(LSTM(lstm_units, return_sequences=False)),\n",
    "                Dropout(0.4),\n",
    "                Dense(64, activation='relu'),\n",
    "                Dropout(0.2),\n",
    "                Dense(n_classes, activation='softmax')\n",
    "            ])\n",
    "            bilstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        else:\n",
    "            # binary\n",
    "            bilstm_model = Sequential([\n",
    "                Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=maxlen),\n",
    "                Bidirectional(LSTM(lstm_units, return_sequences=False)),\n",
    "                Dropout(0.4),\n",
    "                Dense(64, activation='relu'),\n",
    "                Dropout(0.2),\n",
    "                Dense(1, activation='sigmoid')\n",
    "            ])\n",
    "            bilstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        history = bilstm_model.fit(\n",
    "            Xs_train, ys_train,\n",
    "            validation_split=0.1,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Evaluation\n",
    "        probs = bilstm_model.predict(Xs_test, verbose=0)\n",
    "        probs = np.array(probs)\n",
    "        if probs.ndim == 1:\n",
    "            probs = probs.reshape((-1,1))\n",
    "        if probs.shape[1] > 1:\n",
    "            y_pred_bilstm = probs.argmax(axis=1)\n",
    "        else:\n",
    "            y_pred_bilstm = (probs[:,0] >= 0.5).astype(int)\n",
    "\n",
    "        print(\"\\n====== BiLSTM ======\")\n",
    "        print(\"Accuracy:\", accuracy_score(ys_test, y_pred_bilstm))\n",
    "        print(\"Classification Report:\\n\", classification_report(ys_test, y_pred_bilstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1754294254964,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "xuKwRYycE8iJ"
   },
   "outputs": [],
   "source": [
    "# def predict_sentiment(text, model):\n",
    "#     clean = preprocess(text)\n",
    "#     vec = vectorizer.transform([clean])\n",
    "#     result = model.predict(vec)[0]\n",
    "#     return \"Positive\" if result == 1 else \"Negative\"\n",
    "\n",
    "\n",
    "def predict_sentiment(text, model, vectorizer=vectorizer, preprocess_flag=True):\n",
    "    txt = preprocess(text) if preprocess_flag else str(text)\n",
    "    vec = vectorizer.transform([txt])\n",
    "    pred = model.predict(vec)[0]\n",
    "    # If label_classes has more than two items, return mapped label\n",
    "    try:\n",
    "        if len(label_classes) > 2:\n",
    "            return label_classes[pred]\n",
    "    except Exception:\n",
    "        # if label_classes or mapping fails, fall back to numeric return\n",
    "        pass\n",
    "    # binary mapping (assumes positive label is 1)\n",
    "    return \"Positive\" if int(pred) == 1 else \"Negative\"\n",
    "\n",
    "\n",
    "def predict_sentiment_bilstm(text, model=bilstm_model, tokenizer=tokenizer, maxlen=maxlen, preprocess_flag=True):\n",
    "    if model is None or tokenizer is None:\n",
    "        return \"(bilstm not available)\"\n",
    "    txt = preprocess(text) if preprocess_flag else str(text)\n",
    "    seq = tokenizer.texts_to_sequences([txt])\n",
    "    pad = pad_sequences(seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "    probs = model.predict(pad, verbose=0)\n",
    "    probs = np.array(probs)\n",
    "    if probs.ndim == 1:\n",
    "        probs = probs.reshape((-1,1))\n",
    "    if probs.shape[1] > 1:\n",
    "        pred = int(probs.argmax(axis=1)[0])\n",
    "        # map predicted class index back to original label if label_classes exists\n",
    "        try:\n",
    "            return label_classes[pred]\n",
    "        except Exception:\n",
    "            return int(pred)\n",
    "  # multiclass: returns class index (int). Map to labels if you have label names.\n",
    "    else:\n",
    "        pred = 1 if probs[0,0] >= 0.5 else 0\n",
    "        return \"Positive\" if pred == 1 else \"Negative\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1754294254965,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "Js6km4UxE-nY",
    "outputId": "ff51016e-dad2-4738-ac32-d41e2ac7de03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression Prediction:\n",
      "Input: 'I am not happy with the service'\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "NaiveBayes Prediction:\n",
      "Input: 'I am not happy with the service'\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "SVC Prediction:\n",
      "Input: 'I am not happy with the service'\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "BiLSTM Prediction:\n",
      "Input: 'I am not happy with the service'\n",
      "Predicted Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "test_input = \"I am not happy with the service\"\n",
    "\n",
    "for model, name in zip([lr_model, nb_model, svc_model], [\"LogisticRegression\", \"NaiveBayes\", \"SVC\"]):\n",
    "    print(f\"\\n{name} Prediction:\")\n",
    "    print(f\"Input: '{test_input}'\")\n",
    "    print(\"Predicted Sentiment:\", predict_sentiment(test_input, model))\n",
    "\n",
    "\n",
    "# BiLSTM model\n",
    "if bilstm_model is not None and tokenizer is not None:\n",
    "    print(\"\\nBiLSTM Prediction:\")\n",
    "    print(f\"Input: '{test_input}'\")\n",
    "    print(\"Predicted Sentiment:\", predict_sentiment_bilstm(test_input))\n",
    "else:\n",
    "    print(\"\\nBiLSTM model is not available. Train it first before prediction.\")\n",
    "\n",
    "\n",
    "# Save tokenizer and bilstm (if you want persistence)\n",
    "import joblib, os\n",
    "out_dir = \"model_artifacts\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "if tokenizer is not None:\n",
    "    try:\n",
    "        joblib.dump(tokenizer, f\"{out_dir}/tokenizer.joblib\")\n",
    "    except Exception:\n",
    "        print(\"Failed to save tokenizer via joblib.\")\n",
    "if bilstm_model is not None and tf is not None:\n",
    "    try:\n",
    "        bilstm_model.save(os.path.join(out_dir, \"bilstm_model\"), overwrite=True, include_optimizer=False)\n",
    "    except Exception:\n",
    "        bilstm_model.save(os.path.join(out_dir, \"bilstm_model.h5\"), overwrite=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1754294254966,
     "user": {
      "displayName": "AKASH S",
      "userId": "06773098865588466711"
     },
     "user_tz": -330
    },
    "id": "AiPPObox1QS4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOD1JQ6R1vCej4tPaWrLRga",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
